Дано:

В распределенной файловой системе лежат json файлы с описанием работников.

Формат пути:

/data/emp/<код отдела>/<id>.json

Пример:

/data/emp/developers/111.json

{
"name" : "Van Basten",
"salary": "100"
}

/data/emp/managers/777.json

{
"name" : "Rud Gulit",
"salary": "150"
}

/data/emp/hr/555.json

{
"name" : "Diego Maradona",
"salary": "800"
}


Представим себе, что каждый отдел лежит на отдельной датаноде в кластере.

В реале, в домашних условиях - просто в отдельных папках.

Задание:

Написать джоб(spark + scala), который на вход получает список путей к json и:

- прочитает в параллель эти json

- запишет в csv список всех работников c полями : name, salary, department

- затем выведет на экран работника с самой большой зарплатой

- затем выведет на экран сумму зарплат всех работников